{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing analysts accuracy at labelling reference data\n",
    "\n",
    "Collect Earth Online is being used as a tool for collecting cropland reference data.  The sample data contains 'known' labels seeded among the other samples. This script will compare the known test labels (GFSAD's validation data), against the user collected labels.\n",
    "\n",
    "Inputs will be:\n",
    "\n",
    "1. `ceo-data....csv` : The results from collecting training data in the CEO tool\n",
    "\n",
    "Output will be:\n",
    "1. A `confusion error matrix` containing Overall, Producer's, and User's accuracy, along with the F1 score.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/training_validation/collect_earth/eastern/'\n",
    "csv = 'data/training_validation/collect_earth/eastern/ceo-cropland-reference-data-acquisition---eastern-region-sample-data-2020-10-06.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground truth shapefile\n",
    "df = pd.read_csv(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>SMPL_SAMPLEID</th>\n",
       "      <th>SMPL_GFSAD_SAMP</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.707049</td>\n",
       "      <td>12.103541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.681716</td>\n",
       "      <td>4.016547</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>non-crop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.957895</td>\n",
       "      <td>8.458357</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>non-crop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.820614</td>\n",
       "      <td>9.178447</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.940957</td>\n",
       "      <td>-8.582325</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>non-crop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LON        LAT  SMPL_SAMPLEID  SMPL_GFSAD_SAMP  Actual Prediction\n",
       "0  36.707049  12.103541              0                0       2      mixed\n",
       "1  36.681716   4.016547              1                0       1   non-crop\n",
       "2  44.957895   8.458357              2                0       1   non-crop\n",
       "3  40.820614   9.178447              3                0       2      mixed\n",
       "4  33.940957  -8.582325              4                0       1   non-crop"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this line if testing sample:\n",
    "# df = df[['LON', 'LAT', 'SMPL_CLASS','IS THE SAMPLE AREA ENTIRELY: CROP, NON-CROP, MIXED, OR UNSURE?']]\n",
    "\n",
    "#This line if entire dataset:\n",
    "df = df[['LON', 'LAT', 'SMPL_SAMPLEID', 'SMPL_GFSAD_SAMP','SMPL_CLASS','IS THE SAMPLE AREA ENTIRELY: CROP, NON-CROP, MIXED, OR UNSURE?']]\n",
    "\n",
    "#rename columns\n",
    "df = df.rename(columns={'IS THE SAMPLE AREA ENTIRELY: CROP, NON-CROP, MIXED, OR UNSURE?':'Prediction',\n",
    "                        'SMPL_CLASS':'Actual'})\n",
    "\n",
    "#remove nan rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "If this is the `test sample` (first 50-100 samples used for training analysts) then ignore the following cell.\n",
    "\n",
    "If this is the reference data sample (2100) points, then run the cell below to extract the GFSAD validation samples before running the rest of the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['SMPL_GFSAD_SAMP']==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify prediction & actual columns\n",
    "\n",
    "1 = crop, \n",
    "0 = non-crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Prediction'] = np.where(df['Prediction']=='non-crop', 0, df['Prediction'])\n",
    "df['Prediction'] = np.where(df['Prediction']=='crop', 1, df['Prediction'])\n",
    "\n",
    "df['Actual'] = np.where(df['Actual']==1, 0, df['Actual'])\n",
    "df['Actual'] = np.where(df['Actual']==2, 1, df['Actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a confusion matrix with all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>mixed</th>\n",
       "      <th>unsure</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction   0   1  mixed  unsure  All\n",
       "Actual                                \n",
       "0           44   1      3       2   50\n",
       "1            1  40      6       3   50\n",
       "All         45  41      9       5  100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(df['Actual'],\n",
    "                               df['Prediction'],\n",
    "                               rownames=['Actual'],\n",
    "                               colnames=['Prediction'],\n",
    "                               margins=True)\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify into a binary assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 100\n",
      "Number of 'mixed' samples: 9\n",
      "Number of 'unsure' samples: 5\n",
      "Dropping 'mixed' and 'unsure' samples\n"
     ]
    }
   ],
   "source": [
    "counts = df.groupby('Prediction').count()\n",
    "\n",
    "print(\"Total number of samples: \" + str(len(df)))\n",
    "print(\"Number of 'mixed' samples: \"+ str(counts[counts.index=='mixed']['Actual'].values[0]))\n",
    "print(\"Number of 'unsure' samples: \"+ str(counts[counts.index=='unsure']['Actual'].values[0]))\n",
    "\n",
    "print(\"Dropping 'mixed' and 'unsure' samples\")\n",
    "\n",
    "df = df.drop(df[df['Prediction']=='mixed'].index)\n",
    "df = df.drop(df[df['Prediction']=='unsure'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Recreate confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction   0   1  All\n",
       "Actual                 \n",
       "0           44   1   45\n",
       "1            1  40   41\n",
       "All         45  41   86"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(df['Actual'],\n",
    "                               df['Prediction'],\n",
    "                               rownames=['Actual'],\n",
    "                               colnames=['Prediction'],\n",
    "                               margins=True)\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate User's and Producer's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`User's Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix[\"User's\"] = [confusion_matrix.loc[0, 0] / confusion_matrix.loc[0, 'All'] * 100,\n",
    "                              confusion_matrix.loc[1, 1] / confusion_matrix.loc[1, 'All'] * 100,\n",
    "                              np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Producer's Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "producers_accuracy = pd.Series([confusion_matrix[0][0] / confusion_matrix[0]['All'] * 100,\n",
    "                                confusion_matrix[1][1] / confusion_matrix[1]['All'] * 100]\n",
    "                         ).rename(\"Producer's\")\n",
    "\n",
    "confusion_matrix = confusion_matrix.append(producers_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Overall Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.loc[\"Producer's\", \"User's\"] = (confusion_matrix.loc[0, 0] + \n",
    "                                                confusion_matrix.loc[1, 1]) / confusion_matrix.loc['All', 'All'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`F1 Score`\n",
    "\n",
    "The F1 score is the harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall), and is calculated as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Fscore} = 2 \\times \\frac{\\text{UA} \\times \\text{PA}}{\\text{UA} + \\text{PA}}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where UA = Users Accuracy, and PA = Producer's Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore = pd.Series([(2*(confusion_matrix.loc[0, \"User's\"]*confusion_matrix.loc[\"Producer's\", 0]) / (confusion_matrix.loc[0, \"User's\"]+confusion_matrix.loc[\"Producer's\", 0])) / 100,\n",
    "                    f1_score(df['Actual'].astype(np.int8), df['Prediction'].astype(np.int8), average='binary')]\n",
    "                         ).rename(\"F-score\")\n",
    "\n",
    "confusion_matrix = confusion_matrix.append(fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy Confusion Matrix\n",
    "\n",
    "* Limit decimal places,\n",
    "* Add readable class names\n",
    "* Remove non-sensical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round numbers\n",
    "confusion_matrix = confusion_matrix.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename booleans to class names\n",
    "confusion_matrix = confusion_matrix.rename(columns={0:'Non-crop', 1:'Crop', 'All':'Total'},\n",
    "                                            index={0:'Non-crop', 1:'Crop', 'All':'Total'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the nonsensical values in the table\n",
    "confusion_matrix.loc['Total', \"User's\"] = '--'\n",
    "confusion_matrix.loc[\"Producer's\", 'Total'] = '--'\n",
    "confusion_matrix.loc[\"F-score\", 'Total'] = '--'\n",
    "confusion_matrix.loc[\"F-score\", \"User's\"] = '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>Non-crop</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Total</th>\n",
       "      <th>User's</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-crop</th>\n",
       "      <td>44.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>45</td>\n",
       "      <td>97.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crop</th>\n",
       "      <td>1.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>41</td>\n",
       "      <td>97.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>45.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>86</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Producer's</th>\n",
       "      <td>97.78</td>\n",
       "      <td>97.56</td>\n",
       "      <td>--</td>\n",
       "      <td>97.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction  Non-crop   Crop Total User's\n",
       "Actual                                  \n",
       "Non-crop       44.00   1.00    45  97.78\n",
       "Crop            1.00  40.00    41  97.56\n",
       "Total          45.00  41.00    86     --\n",
       "Producer's     97.78  97.56    --  97.67\n",
       "F-score         0.98   0.98    --     --"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.to_csv(folder+ 'test_sample_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
